% vim: ts=4 sts=4 sw=4 et tw=75
\chapter{Notation}
\label{chap:notation}
\begin{quote}
    Perhaps of all the creations of man language is the most astonishing
    (惊讶的).
\end{quote}
\begin{quotesrc}
    Giles Lytton Strachey, \bookname{Words and Poetry}
\end{quotesrc}

The right language can make all the difference in how easy it is to write a
program. This is why a practicing programmer's arsenal holds not only
general-purpose languages like C and its relatives, but also programmable
shells, scripting languages, and lots of application-specific languages

The power of good notation reaches beyond traditional programming into
specialized problem domains. Regular expressions let us write compact (if
occasionally cryptic (神秘的)) definitions of classes of strings; HTML lets
us define the layout of interactive documents, often using embedded
programs in other languages such as JavaScript; Postscript expresses an
entire document -- this book, for example -- as a stylized program.
Spreadsheets and word processors often include programming languages like
Visual Basic to evaluate expressions, access information, or control
layout.

If you find yourself writing too much code to do a mundane (平凡的) job, or
if you have trouble expressing the process comfortably, maybe you're using
the wrong language. If the right language doesn't yet exist, that might be
an opportunity to create it yourself. Inventing a language doesn't
necessarily mean building the successor to Java; often a thorny (多刺的)
problem can be cleared up by a change of notation. Consider the format
strings in the \verb'printf' family, which are a compact and expressive way
to control the display of printed values.

In this chapter, we'll talk about how notation can solve problems, and
demonstrate some of the techniques you can use to implement your own
special-purpose languages. We'll even explore the possibilities of having
one program write another program, an apparently extreme use of notation
that happens more often, and is far easier to do, than many programmers
realize.

\section{Formatting Data}
\label{sec:formatting_data}

There is always a gap between what we want to say to the computer ("solve
my problem") and what we are required to say to get a job done. The
narrower this gap, the better. Good notation makes it easier to say what we
want and harder to say the wrong thing by mistake. Sometimes, good notation
can provide new insight (见识, 洞察), allowing us to solve problems that
seemed too difficult, or even lead us to new discoveries.

\textbf{\texttt{Little languages}} are specialized notations for narrow
domains. They not only provide a good interface but also help organize the
program that implements them. The \verb'printf' control sequences are a
good example:
\begin{wellcode}
    printf("%d %6.2f %-10.10s\n", i, f, s);
\end{wellcode}

Each \verb'%' in the format string signals a place to interpolate (插入)
the value of the next \verb'printf' argument; after some optional flags and
field widths, the terminating letter says what kind of parameter to expect.
This notation is compact, intuitive, and easy to write, and the
implementation is straightforward. The alternatives in C++
(\verb'iostream') and Java (\verb'java.io') seem more awkward (笨拙) since
they don't provide special notation, although they extend to user-defined
types and offer type-checking.

Some non-standard implementations of \verb'printf' let you add your own
conversions to the built-in set. This is convenient if you have other data
types that need output conversion. For example, a compiler might use
\verb'%L' for line number and file name; a graphics system might use
\verb'%P' for a point and \verb'%R' for a rectangle. The cryptic string of
letters and numbers for retrieving stock quotes (股价报价) that we saw in
Chapter \ref{chap:interface} was in the same spirit, a compact notation for
arranging (编排) combinations of stock data.

We can synthesize similar examples in C and C++. Suppose we want to send
packets containing various combinations of data types from one system to
another.  As we saw in Chapter \ref{chap:portability}, the cleanest
solution may be to convert to a textual representation. For a standard
network protocol, though, the format is likely to be binary for reasons of
efficiency or size. How can we write the packet-handling code to be
portable, efficient, and easy to use?

To make this discussion concrete, imagine that we plan to send packets of
8-bit, 16-bit, and 32-bit data items from system to system. ANSI C says
that we can always store at least 8 bits in a \verb'char', 16 bits in a
\verb'short', and 32 bits in a \verb'long', so we will use these data types
to represent our values. There will be many types of packets; packet type 1
might have a 1-byte type specifier, a 2-byte count, a 1-byte value and a
4-byte data item:
\begin{center}
    \begin{tikzpicture}
        \pgfmathsetmacro\width{1.5};

        \draw (0, 0) -- (\width * 8, 0);
        \draw (0, 1) -- (\width * 8, 1);
        \foreach \i in {0, ..., 8}
        \draw (\i * \width, 0) -- (\i * \width, 1);

        \newcounter{j};
        \setcounter{j}{0};
        \foreach \ind/\data in { 0/\texttt{0x01}, 1/\texttt{cnt$_1$},
            2/\texttt{cnt$_0$}, 3/\texttt{val}, 4/\texttt{data$_3$},
            5/\texttt{data$_2$}, 6/\texttt{data$_1$},
            7/\texttt{data$_0$}} {

            \node at (\arabic{j} * \width + \width / 2, 0.5)
                {\data};
            \addtocounter{j}{1};
        }
    \end{tikzpicture}
\end{center}
Packet type 2 might contain a short and two long data words:
\begin{center}
    \begin{tikzpicture}
        \pgfmathsetmacro\width{1.5};

        \draw (0, 0) -- (\width * 11, 0);
        \draw (0, 1) -- (\width * 11, 1);
        \foreach \i in {0, ..., 11}
        \draw (\i * \width, 0) -- (\i * \width, 1);

        \setcounter{j}{0};
        \foreach \ind/\data in { 0/\texttt{0x02}, 1/\texttt{cnt$_1$},
            2/\texttt{cnt$_0$}, 3/\texttt{dw1$_3$},
            4/\texttt{dw1$_2$}, 5/\texttt{dw1$_1$},
            6/\texttt{dw1$_0$}, 7/\texttt{dw2$_3$}, 8/\texttt{dw2$_2$},
            9/\texttt{dw2$_1$}, 10/\texttt{dw2$_0$}} {

            \node at (\arabic{j} * \width + \width / 2, 0.5)
                {\data};
            \addtocounter{j}{1};
        }
    \end{tikzpicture}
\end{center}

One approach is to write pack and unpack functions for each possible packet
type:
\begin{wellcode}
    int pack_type1(unsigned char *buf, unsigned short count,
            unsigned char val, unsigned long data)
    {
        unsigned char *bp;

        bp = buf;
        *bp++ = 0x01;
        *bp++ = count >> 8;
        *bp++ = count;
        *bp++ = val;
        *bp++ = data >> 24;
        *bp++ = data >> 16;
        *bp++ = data >> 8;
        *bp++ = data;
        return bp - buf;
    }
\end{wellcode}
For a realistic protocol, there will be dozens of such routines, all
variations on a theme. The routines could be simplified by using macros or
functions to handle the basic data types (\verb'short', \verb'long', and so
on), but even so, such repetitive code is easy to get wrong, hard to read,
and hard to maintain.

The inherent (固有的) repetitiveness (重复性) of the code is a clue that
notation can help.  Borrowing the idea from \verb'printf', we can define a
tiny specification language in which each packet is described by a brief
string that captures the packet layout.  Successive elements of the packet
are encoded with \verb'c' for an 8-bit character, \verb's' for a 16-bit
short integer, and \verb'l' for a 32-bit long integer. Thus, for example,
the packet type 1 built by our example above, including the initial type
byte, might be described by the format string \verb'cscl'. Then we can use
a single pack function to create packets of any type; this packet would be
created with
\begin{wellcode}
    pack(buf, "cscl", 0x01, count, val, data);
\end{wellcode}
Because our format string contains only data definitions, there's no need
for the \verb'%' character used by \verb'printf'.

In practice, information at the beginning of the packet might tell the
recipient (接受者) how to decode the rest, but we'll assume the first byte
of the packet can be used to determine the layout. The sender encodes the
data in this format and ships it; the receiver reads the packet, picks off
the first byte, and uses that to decode what follows.

Here is an implementation of \verb'pack', which fills \verb'buf' with the
encoded representation of its arguments as determined by the format. We
make all values unsigned, including the bytes in the packet buffer, to
avoid sign-extension problems.  We also use some conventional
\verb'typedef's to keep the declarations short:
\begin{wellcode}
    typedef unsigned char   uchar;
    typedef unsigned short  ushort;
    typedef unsigned long   ulong;
\end{wellcode}
Like \verb'sprintf', \verb'strcpy', and similar functions, \verb'pack'
assumes that the buffer is big enough to hold the result; it is the
caller's responsibility to ensure this. There is also no attempt to detect
mismatches between the format and the argument list.
\begin{wellcode}
    #include <stdarg.h>

    /* pack: pack binary items into buf, return length */
    int pack(uchar *buf, char *fmt, ...)
    {
        va_list args;
        char    *p;
        uchar   *bp;
        ushort  s;
        ulong   l;
        bp = buf;
        va_start(args, fmt);
        for (p = fmt; *p != '\0'; p++) {
            switch (*p) {
            case 'c':   /* char */
                *bp++ = va_arg(args, int);
                break;
            case 's':   /* short */
                s = va_arg(args, int);
                *bp++ = s >> 8;
                *bp++ = s;
                break;
            case 'l':   /* long */
                l = va_arg(args, ulong);
                *bp++ = l >> 24;
                *bp++ = l >> 16;
                *bp++ = l >> 8;
                *bp++ = l;
                break;
            default:    /* illegal type character */
                va_end(args);
                return -1;
            }
        }
        va_end(args);
        return bp - buf;
    }
\end{wellcode}

The \verb'pack' routine uses the \verb'stdarg.h' header more extensively
than \verb'eprintf' did in Chapter \ref{chap:interface}. The successive
arguments are extracted using the macro \verb'va_arg', with first operand
the variable of type \verb'va_list' set up by calling \verb'va_start' and
second operand the type of the argument (this is why \verb'va_arg' is a
macro, not a function).  When processing is done, \verb'va_end' must be
called. Although the arguments for \verb"'c'" and \verb"'s'" represent
\verb'char' and \verb'short' values, they must be extracted as \verb'int's
because C promotes (提升) \verb'char' and \verb'short' arguments to
\verb'int' when they are represented by an ellipsis \verb'...'  parameter.

Each \verb'pack_type' routine will now be one line long, marshaling
(封装处理) its arguments into a call of \verb'pack':
\begin{wellcode}
    /* pack_type1: pack format 1 packet */
    int pack_type1(uchar *buf, ushort count, uchar val, ulong data)
    {
        return pack(buf, "cscl", 0x01, count, val, data);
    }
\end{wellcode}

To unpack, we can do the same thing: rather than write separate code to
crack each packet format, we call a single \verb'unpack' with a format
string. This centralizes the conversion in one place:
\begin{wellcode}
    /* unpack: unpack packed items from buf, return length */
    int unpack(uchar *buf, char *fmt, ...)
    {
        va_list args;
        char    *p;
        uchar   *bp, *pc;
        ushort  *ps;
        ulong   *pl;

        bp = buf;
        va_start(args, fmt);
        for (p = fmt; *p != '\0'; p++) {
            switch (*p) {
            case 'c':   /* char */
                pc = va_arg(args, uchar *);
                *pc = *bp++;
                break;
            case 's':   /* short */
                ps = va_arg(args, ushort *);
                *ps = *bp++ << 8;
                *ps |= *bp++;
                break;
            case 'l':   /* long */
                pl = va_arg(args, ulong *);
                *pl = *bp++ << 24;
                *pl |= *bp++ << 16;
                *pl |= *bp++ << 8;
                *pl |= *bp++;
                break;
            default:    /* illegal type character */
                va_end(args);
                return -1;
            }
        }
        va_end(args);
        return bp - buf;
    }
\end{wellcode}
Like \verb'scanf', \verb'unpack' must return multiple values to its caller,
so its arguments are pointers to the variables where the results are to be
stored. Its function value is the number of bytes in the packet, which can
be used for error checking.

Because the values are unsigned and because we stayed within the sizes that
ANSI C defines for the data types, this code transfers data portably even
between machines with different sizes for \verb'short' and \verb'long'.
Provided (倘若) the program that uses \verb'pack' does not try to send as a
long (for example) a value that cannot be represented in 32 bits, the value
will be received correctly. In effect, we transfer the low 32 bits of the
value.  If we need to send larger values, we could define another format.

The type-specific unpacking routines that call \verb'unpack' are easy:
\begin{wellcode}
    /* unpack_type2: unpack and process type 2 packet */
    int unpack_type2(int n, uchar *buf)
    {
        uchar   c;
        ushort  count;
        ulong   dw1, dw2;

        if (unpack(buf, "csll", &c, &count, &dw1, &dw2) != n)
            return -1;
        assert(c == 0x02);
        return process_type2(count, dw1, dw2);
    }
\end{wellcode}
To call \verb'unpack_type2', we must first recognize that we have a type 2
packet, which implies a receiver loop something like this:
\begin{wellcode}
    while ((n = readpacket(network, buf, BUFSIZ)) > 0) {
        switch (buf[0]) {
        default:
            eprintf("bad packet type 0x%x", buf[0]);
            break;
        case 1:
            unpack_type1(n, buf);
            break;
        case 2:
            unpack_type2(n, buf);
            break:
        ...
        }
    }
\end{wellcode}
This style of programming can get long-winded (冗长的). A more compact
method is to define a table of function pointers whose entries are the
unpacking routines indexed by type:
\begin{wellcode}
    int (*unpackfn[])(int, uchar *) = {
        unpack_type0,
        unpack_type1,
        unpack_type2,
    };
\end{wellcode}
Each function in the table parses a packet, checks the result, and
initiates further processing for that packet. The table makes the
recipient's job straightforward:
\begin{wellcode}
    /* receive: read packets from network, process them */
    void receive(int network)
    {
        uchar   type, buf[BUFSIZ];
        int     n;

        while ((n = readpacket(network, buf, BUFSIZ)) > 0) {
            type = buf[0];
            if (type >= NELEMS(unpackfn))
                eprintf("bad packet type 0x%x", type);
            if ((*unpackfn[type](n, buf) < 0)
                eprintf("protocol error, type %x length %d",
                        type, n);
        }
    }
\end{wellcode}
Each packet's handling code is compact, in a single place, and easy to
maintain. The receiver is largely independent of the protocol itself; it's
clean and fast, too.

This example is based on some real code for a commercial networking
protocol.  Once the author realized this approach could work, a few
thousand repetitive, error-prone (容易出错的) lines of code shrunk (压缩)
to a few hundred lines that are easily maintained. Notation reduced the
mess enormously.

\begin{exercise}
    Modify \verb'pack' and \verb'unpack' to transmit signed values
    correctly, even between machines with different sizes for \verb'short'
    and \verb'long'. How should you modify the format strings to specify a
    signed data item? How can you test the code to check, for example, that
    it correctly transfers a \verb'-1' from a computer with 32-bit
    \verb'long's to one with 64-bit \verb'long's?
\end{exercise}
\begin{exercise}
    Extend \verb'pack' and \verb'unpack' to handle strings; one possibility
    is to include the length of the string in the format string. Extend
    them to handle repeated items with a count. How does this interact with
    the encoding of strings?
\end{exercise}
\begin{exercise}
    The table of function pointers in the C program above is at the heart
    of C++'s virtual function mechanism. Rewrite \verb'pack' and
    \verb'unpack' and receive in C++ to take advantage of this notational
    convenience.
\end{exercise}
\begin{exercise}
    Write a command-line version of \verb'printf' that prints its second
    and subsequent arguments in the format given by its first argument.
    Some shells already provide this as a built-in.
\end{exercise}
\begin{exercise}
    Write a function that implements the format specifications found in
    spreadsheet programs or in Java's \verb'DecimalFormat' class, which
    display numbers according to patterns that indicate mandatory and
    optional digits, location of decimal points and commas, and so on. To
    illustrate, the format
    \begin{wellcode}
        ##,##0.00
    \end{wellcode}
    specifies a number with two decimal places, at least one digit to the
    left of the decimal point, a comma after the thousands digit, and
    blank-filling up to the ten-thousands It would represent
    \verb'12345.67' as \verb'12,345.67' and \verb'.4' as
    \texttt{\textvisiblespace\textvisiblespace
        \textvisiblespace\textvisiblespace0.4} (using \textvisiblespace 
    \ to stand for blanks). For a full specification, look at the definition
    of \verb'DecimalFormat' or a spreadsheet program.
\end{exercise}

\section{Regular Expressions}
\label{sec:regular_expressions}

The format specifiers (说明) for \verb'pack' and \verb'unpack' are a very
simple notation for defining the layout of packets. Our next topic is a
slightly more complicated but much more expressive notation,
\textbf{\textit{regular expressions}}, which specify patterns of text.
We've used regular expressions occasionally throughout the book without
defining them precisely; they are familiar enough to be understood without
much explanation.  Although regular expressions are pervasive (无孔不入的)
in the Unix programming environment, they are not as widely used in other
systems, so in this section we'll demonstrate some of their power. In case
you don't have a regular expression library handy, we'll also show a
rudimentary (低级的) implementation.

There are several flavors (滋味) of regular expressions, but in spirit they
are all the same, a way to describe patterns of literal characters, along
with repetitions, alternatives, and shorthands (简写) for classes of
characters like digits or letters. One familiar example is the so-called
"wildcards" used in command-line processors or shells to match patterns of
file names. Typically a is taken to mean "any string of characters" so, for
example, a command like
\begin{wellcode}
    C:\>del *.exe
\end{wellcode}
uses a pattern that matches all files whose names consist of any string
ending in \verb'".exe"'. As in often the case, details differ from system
to system, and even from program to program.

Although the vagaries (奇特行为) of different programs may suggest that
regular expressions are an ad hoc (特别设的) mechanism, in fact they are a
language with a formal grammar and a precise meaning for each utterance
(言辞) in the language. Furthermore, the right implementation can run very
fast; a combination of theory and engineering practice makes a lot of
difference (造成了很多差异), an example of the benefit of specialized
algorithms that we alluded (提及) to in Chapter \ref{chap:alds}.

A regular expression is a sequence of characters that defines a set of
matching strings. Most characters simply match themselves, so the regular
expression \verb'abc' will match that string of letters wherever it occurs.
In addition a few metacharacters indicate repetition or grouping or
positioning. In conventional Unix regular expressions, \verb'^' stands for
the beginning of a string and \verb'$' for the end, so \verb'^x' matches an
\verb'x' only at the beginning of a string. \verb'x$' matches an \verb'x'
only at the end, \verb'^x$' matches \verb'x' only if it is the sole
(仅有的) character of the string, and \verb'^$' matches the empty string.

The character "\verb'.'" matches any character, so \verb'x.y' matches
\verb'xay', \verb'x2y' and so on, but not \verb'xy' or \verb'xaby', and
\verb'^.$' matches a string with a single arbitrary character.

A set of characters inside brackets \verb'[]' matches any one of the
enclosed characters, so \verb'[0123456789]' matches a single digit; it may
be abbreviated \verb'[0-9]'.

These building blocks are combined with parentheses for grouping, \verb'|'
for alternatives, \verb'*' for zero or more occurrences, \verb'+' for one or
more occurrences, and \verb'?' for zero or one occurrences. Finally, \verb'\'
is used as a prefix to quote a metacharacter and turn off its special
meaning; \verb'\*' is a literal \verb'*' and \verb'\\' is a literal
backslash.

The best-known regular expression tool is the program \verb'grep' that
we've mentioned several times. The program is a marvelous (了不起的)
example of the value of notation.  It applies a regular expression to each
line of its input files and prints those lines that contain matching
strings. This simple specification, plus the power of regular expressions,
lets it solve many day-to-day (日复一日) tasks. In the following examples,
note that the regular expression syntax used in the argument to \verb'grep'
is different from the wildcards used to specify a set of file names; this
difference reflects the different uses.

Which source file uses class \verb'Regexp'?
\begin{wellcode}
    % grep Regexp *.java
\end{wellcode}

Which implements it?
\begin{wellcode}
    % grep 'class.*Regexp' *.java
\end{wellcode}

Where did I save that mail from Bob?
\begin{wellcode}
    grep '^From:.* bob@' mail/*
\end{wellcode}

How many non-blank source lines are there in this program?
\begin{wellcode}
    % grep '.' *.cpp | wc
\end{wellcode}

With flags to print line numbers of matched lines, count matches, do case-
insensitive matching, invert the sense (select lines that don't match the
pattern), and perform other variations of the basic idea, \verb'grep' is so
widely used that it has become the classic example of tool-based
programming.

Unfortunately, not every system comes with \verb'grep' or an equivalent.
Some systems include a regular expression library, usually called
\verb'regex' or \verb'regexp', that you can use to write a version of
\verb'grep'. If neither option is available, it's easy to implement a
modest (适度的) subset of the full regular expression language. Here we
present an implementation of regular expressions, and \verb'grep' to go
along with it; for simplicity, the only metacharacters are \verb'^ $'. and
\verb'*', with \verb'*' specifying a repetition of the single previous
period (片段) or literal character. This subset provides a large fraction
of the power with a tiny fraction of the programming complexity of general
expressions.

Let's start with the \verb'match' function itself, Its job is to determine
whether a text string matches a regular expression:
\begin{wellcode}
    /* match: search for regexp anywhere in text */
    int match(char *regexp, char *text)
    {
        if (regexp[0] == '^')
            return matchhere(regexp+1, text);
        do {    /* must look even if string is empty */
            if (matchhere(regexp, text))
                return 1;
        } while (*text++ != '\0');
        return 0;
    }
\end{wellcode}
If the regular expression begins with \verb'^', the text must begin with a
match of the remainder of the expression. Otherwise, we walk along the
text, using \verb'matchhere' to see if the text matches at any position. As
soon as we find a match, we're done. Note the use of a \verb'do-while':
expressions can match the empty string (for example, \verb'$' matches the
empty string at the end of a line and \verb'.*' matches any number of
characters, including zero), so we must call matchhere even if the text is
empty.

The recursive function \verb'matchhere' does most of the work:
\begin{wellcode}
    /* matchhere: search for regexp at beginning of text */
    int matchhere(char *regexp, char *text)
    {
        if (regexp[0] == '\0')
            return 1;
        if (regexp[1] == '*')
            return matchstar(regexp[0], regexp+2, text);
        if (regexp[0] == '$' && regexp[1] == '\0')
            return *text == '\0';
        if (*text != '\0' && (regexp[0] == '.' || regexp[0] == *text))
            return matchhere(regexp+1, text+1);
        return 0;
    }
\end{wellcode}
If the regular expression is empty, we have reached the end and thus have
found a match. If the expression ends with \verb'$', it matches only if the
text is also at the end. If the expression begins with a period, that
matches any character. Otherwise the expression begins with a plain
character that matches itself in the text. A \verb'^' or \verb'$' that
appears in the middle of a regular expression is thus taken as a literal
character, not a metacharacter.

Notice that matchhere calls itself after matching one character of pattern
and string, so the depth of recursion can be as much as the length of the
pattern.

The one tricky case occurs when the expression begins with a starred
character, for example \verb'x*'. Then we call \verb'matchstar', with first
argument the operand of the star (\verb'x') and subsequent arguments the
pattern after the star and the text.
\begin{wellcode}
    /* matchstar: search for c*regexp at beginning of text */
    int matchstar(int c, char *regexp, char *text)
    {
        do {    /* a * matches zero or more instances */
            if (matchhere(regexp, text))
                return 1;
        } while (*text != '\0' && (*text++ == c || c == '.'));
        return 0;
    }
\end{wellcode}
Here is another \verb'do-while', again triggered by the requirement that
the regular expression \verb'x*' can match zero characters. The loop checks
whether the text matches the remaining expression, trying at each position
of the text as long as the first character matches the operand of the star.

This is an admittedly (诚然地) unsophisticated implementation, but it
works, and at fewer than 30 lines of code, it shows that regular
expressions don't need advanced techniques to be put to use.

We'll soon present some ideas for extending the code. For now, though,
let's write a version of \verb'grep' that uses \verb'match'. Here is the
main routine:
\begin{wellcode}
    /* grep main: search for regexp in files */
    int main(int argc, char *argv[])
    {
        int     i, nmatch;
        FILE    *f;

        setprogname("grep");
        if (argc < 2)
            eprintf("usage: grep regexp [file ...]");
        nmatch = 0;
        if (argc == 2) {
            if (grep(argv[1], stdin, NULL))
                nmatch++;
        } else {
            for (i = 2; i < argc; i++) {
                f = fopen(argv[i], "r");
                if (f == NULL) {
                    weprintf("can't open %s:", argv[i]);
                    continue;
                }
                if (grep(argv[1], f, argc > 3 ? argv[i] : NULL) > 0)
                    nmatch++;
                fclose(f);
            }
        }
        return nmatch == 0;
    }
\end{wellcode}
It is conventional that C programs return 0 for success and non-zero values
for various failures. Our \verb'grep', like the Unix version, defines
success as finding a matching line, so it returns \verb'0' if there were
any matches, \verb'1' if there were none, and \verb'2' (via \verb'eprintf')
if an error occurred. These status values can be tested by other programs
like a shell.

The function \verb'grep' scans a single file, calling
\verb'match' on each line:
\begin{wellcode}
    /* grep: search for regexp in file */
    int grep(char *regexp, FILE *f, char *name)
    {
        int     n, nmatch;
        char    buf[BUFSIZ];

        nmatch = 0;
        while (fgets(buf, sizeof(buf), f) != NULL) {
            n = strlen(buf);
            if (n > 0 && buf[n-1] == '\n')
                buf[n-1] = '\0';
            if (match(regexp, buf)) {
                nmatch++;
                if (name != NULL)
                    printf("%s: ", name);
                printf("%s\n", buf);
            }
        }
        return nmatch;
    }
\end{wellcode}

The main routine doesn't quit if it fails to open a file. This design was
chose because it's common to say something like
\begin{wellcode}
    % grep herpolhode *.*
\end{wellcode}
and find that one of the files in the directory can't be read. It's better
for \verb'grep' to keep going after reporting the problem, rather than to
give up and force the user to type the file list manually to avoid the
problem file. Also, notice that \verb'grep' prints the file name and the
matching line, but suppresses the name if it is reading standard input or a
single file. This may seem an odd (古怪的) design, but it reflects an
idiomatic style of use based on experience. When given only one input,
\verb'grep''s task is usually selection, and the file name would clutter
(弄乱) the output. But if it is asked to search through many files, the
task is most often to find all occurrences of something, and the names are
informative. Compare
\begin{wellcode}
    % strings markov.exe | grep 'DOS mode'
\end{wellcode}
with
\begin{wellcode}
    % grep grammer chapter*.txt
\end{wellcode}
These touches are part of what makes \verb'grep' so popular, and
demonstrate that notation must be packaged with human engineering to build
a natural, effective tool.

Our implementation of \verb'match' returns as soon as it finds a match. For
\verb'grep', that is a fine default. But for implementing a substitution
(search-and-replace) operator in a text editor the \textit{\textbf{leftmost
longest}} match is more suitable. For example, given the text
\verb'"aaaaa"' the pattern \verb'a*' matches the null string at the
beginning of the text, but it seems more natural to match all five
\verb'a''s. To cause \verb'match' to find the leftmost longest string,
\verb'matchstar' must be rewritten to be greedy: rather than looking at
each character of the text from left to right, it should skip over the
longest string that matches the starred operand, then back up (倒退) if the
rest of the string doesn't match the rest of the pattern. In other words,
it should run from right to left. Here is a version of \verb'matchstar'
that does leftmost longest matching:
\begin{wellcode}
    /* matchstar: leftmost longest search for c*regexp */
    int matchstar(int c, char *regexp, char *text)
    {
        char    *t;

        for (t = text; *t != '\0' && (*t == c || c == '.');
                t++)
            ;
        do {    /* matches zero or more */
            if (matchhere(regexp, t))
                return 1;
        } while (t-- > text);
        return 0;
    }
\end{wellcode}
It doesn't matter which match \verb'grep' finds, since it is just checking
for the presence of any match and printing the whole line. So since
leftmost longest matching does extra work, it's not necessary for
\verb'grep', but for a substitution operator, it is essential.

Our \verb'grep' is competitive with system-supplied versions, regardless of
the regular expression. There are pathological (错误的) expressions that
can cause exponential behavior, such as \verb'a*a*a*a*a*b' when given the
input \verb'aaaaaaaaac', but the exponential behavior is present in some
commercial implementations too. A \verb'grep' variant available on Unix,
called \verb'egrep', uses a more sophisticated matching algorithm that
guarantees linear performance by avoiding backtracking when a partial match
fails.

What about making \verb'match' handle full regular expressions? These would
include character classes like \verb'[a-zA-Z]' to match an alphabetic
character, the ability to quote a metacharacter (for example to search for
a literal period), parentheses for grouping, and alternatives (\verb'abc'
or \verb'def'). The first step is to help \verb'match' by compiling the
pattern into a representation that is easier to scan. It is expensive to
parse a character class every time we compare it against a character; a
pre-computed representation based on bit vectors could make character
classes much more efficient. For full regular expressions, with parentheses
and alternatives, the implementation must be more sophisticated, but can
use some of the techniques we'll talk about later in this chapter.

\begin{exercise}
    How does the performance of \verb'match' compare to \verb'strstr' when
    searching for plain text?
\end{exercise}

\begin{exercise}
    Write a non-recursive version of \verb'matchhere' and compare its
    performance to the recursive version.
\end{exercise}

\begin{exercise}
    Add some options to \verb'grep'. Popular ones include \verb'-v' to
    invert the sense of the \verb'match'. \verb'-i' to do case-insensitive
    matching of alphabetics, and \verb'-n' to include line numbers in the
    output. How should the line numbers be printed? Should they be printed
    on the same line as the matching text?
\end{exercise}

\begin{exercise}
    Add the \verb'+' (one or more) and \verb'?' (zero or one) operators to
    \verb'match'. The pattern \verb'a+bb?' matches one or more \verb'a''s
    followed by one or two \verb'b''s.
\end{exercise}

\begin{exercise}
    The current implementation of match turns off the special meaning of
    \verb'^' and \verb'$' if they don't begin or end the expression, and of
    \verb'*' if it doesn't immediately follow a literal character or a
    period. A more conventional design is to quote a metacharacter by
    preceding it with a backslash. Fix \verb'match' to handle backslashes
    this way.
\end{exercise}

\begin{exercise}
    Add character classes to \verb'match'. Character classes specify a
    match for any one of the characters in the brackets. They can be made
    more convenient by adding ranges, for example \verb'[a-z]' to match any
    lower-case letter, and inverting the sense, for example \verb'[^O-9]'
    to match any character except a digit.
\end{exercise}

\begin{exercise}
    Change \verb'match' to use the leftmost-longest version of
    \verb'matchstar', and modify it to return the character positions of
    the beginning and end of the matched text. Use that to build a program
    \verb'gres' that is like \verb'grep' but prints every input line after
    substituting new text for text that matches the pattern, as in
    \begin{wellcode}
        % grep 'homoiousian' 'homoousian' mission.stmt
    \end{wellcode}
\end{exercise}

\begin{exercise}
    Modify \verb'match' and \verb'grep' to work with UTF-8 strings of
    Unicode characters. Because UTF-8 and Unicode are a superset of ASCII,
    this change is upwardly compatible. Regular expressions, as well as the
    searched text, will also need to work properly with UTF-8. How should
    character classes be implemented?
\end{exercise}

\begin{exercise}
    Write an automatic tester for regular expressions that generates test
    expressions and test strings to search. If you can, use an existing
    library as a reference implementation; perhaps you will find bugs in it
    too.
\end{exercise}
